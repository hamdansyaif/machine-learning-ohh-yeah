{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90730801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FUNCTIONAL API & SUBCLASSING\n",
      "============================================================\n",
      "TensorFlow version: 2.15.0\n",
      "\n",
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 1: Import Libraries & Setup\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow & Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FUNCTIONAL API & SUBCLASSING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(\"\\n‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e640e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA PREPARATION\n",
      "============================================================\n",
      "\n",
      "üìä Data Loaded:\n",
      "  Training: 13,209 samples\n",
      "  Validation: 3,303 samples\n",
      "  Test: 4,128 samples\n",
      "  Features: 8\n",
      "\n",
      "‚úÖ Data preparation completed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 2: Load & Prepare Housing Data\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA PREPARATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create synthetic housing data (same as Notebook 2)\n",
    "np.random.seed(42)\n",
    "n_samples = 20640\n",
    "\n",
    "# Generate features\n",
    "X_housing = np.random.randn(n_samples, 8)\n",
    "\n",
    "# Generate target\n",
    "y_housing = (\n",
    "    3.0 * X_housing[:, 0] + \n",
    "    -0.5 * X_housing[:, 1] + \n",
    "    1.5 * X_housing[:, 2] + \n",
    "    -1.0 * X_housing[:, 3] + \n",
    "    0.3 * X_housing[:, 4] + \n",
    "    np.random.randn(n_samples) * 0.5\n",
    ")\n",
    "y_housing = (y_housing - y_housing.min()) / (y_housing.max() - y_housing.min()) * 4 + 0.5\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nüìä Data Loaded:\")\n",
    "print(f\"  Training: {X_train_scaled.shape[0]:,} samples\")\n",
    "print(f\"  Validation: {X_valid_scaled.shape[0]:,} samples\")\n",
    "print(f\"  Test: {X_test_scaled.shape[0]:,} samples\")\n",
    "print(f\"  Features: {X_train_scaled.shape[1]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Data preparation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58712d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "API COMPARISON: SEQUENTIAL vs FUNCTIONAL vs SUBCLASSING\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ SEQUENTIAL API\n",
      "------------------------------------------------------------\n",
      "‚úÖ Pros:\n",
      "  ‚Ä¢ Simple and intuitive\n",
      "  ‚Ä¢ Easy to use for beginners\n",
      "  ‚Ä¢ Linear stack of layers\n",
      "\n",
      "‚ùå Cons:\n",
      "  ‚Ä¢ Only for sequential models\n",
      "  ‚Ä¢ Cannot handle multiple inputs/outputs\n",
      "  ‚Ä¢ No shared layers or complex topologies\n",
      "\n",
      "üìä Sequential Model:\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1231 (4.81 KB)\n",
      "Trainable params: 1231 (4.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "‚úÖ Sequential API demonstrated!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 3: Sequential API - Quick Recap\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"API COMPARISON: SEQUENTIAL vs FUNCTIONAL vs SUBCLASSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ SEQUENTIAL API\")\n",
    "print(\"-\" * 60)\n",
    "print(\"‚úÖ Pros:\")\n",
    "print(\"  ‚Ä¢ Simple and intuitive\")\n",
    "print(\"  ‚Ä¢ Easy to use for beginners\")\n",
    "print(\"  ‚Ä¢ Linear stack of layers\")\n",
    "print(\"\\n‚ùå Cons:\")\n",
    "print(\"  ‚Ä¢ Only for sequential models\")\n",
    "print(\"  ‚Ä¢ Cannot handle multiple inputs/outputs\")\n",
    "print(\"  ‚Ä¢ No shared layers or complex topologies\")\n",
    "\n",
    "# Example Sequential Model\n",
    "model_sequential = keras.Sequential([\n",
    "    layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    layers.Dense(30, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "print(\"\\nüìä Sequential Model:\")\n",
    "model_sequential.summary()\n",
    "\n",
    "print(\"\\n‚úÖ Sequential API demonstrated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4dfbe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FUNCTIONAL API - BASIC EXAMPLE\n",
      "============================================================\n",
      "\n",
      "2Ô∏è‚É£ FUNCTIONAL API\n",
      "------------------------------------------------------------\n",
      "‚úÖ Pros:\n",
      "  ‚Ä¢ Flexible architecture\n",
      "  ‚Ä¢ Multiple inputs/outputs\n",
      "  ‚Ä¢ Shared layers\n",
      "  ‚Ä¢ Complex topologies (DAG)\n",
      "\n",
      "‚ùå Cons:\n",
      "  ‚Ä¢ Slightly more verbose\n",
      "  ‚Ä¢ Requires understanding of data flow\n",
      "\n",
      "üìä Functional Model (Same Architecture as Sequential):\n",
      "Model: \"functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 8)]               0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1231 (4.81 KB)\n",
      "Trainable params: 1231 (4.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "üîç Key Differences:\n",
      "  ‚Ä¢ Sequential: model = Sequential([layers...])\n",
      "  ‚Ä¢ Functional: define inputs ‚Üí connect layers ‚Üí create Model()\n",
      "\n",
      "‚úÖ Functional API demonstrated!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 4: Functional API - Basic Example\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FUNCTIONAL API - BASIC EXAMPLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ FUNCTIONAL API\")\n",
    "print(\"-\" * 60)\n",
    "print(\"‚úÖ Pros:\")\n",
    "print(\"  ‚Ä¢ Flexible architecture\")\n",
    "print(\"  ‚Ä¢ Multiple inputs/outputs\")\n",
    "print(\"  ‚Ä¢ Shared layers\")\n",
    "print(\"  ‚Ä¢ Complex topologies (DAG)\")\n",
    "print(\"\\n‚ùå Cons:\")\n",
    "print(\"  ‚Ä¢ Slightly more verbose\")\n",
    "print(\"  ‚Ä¢ Requires understanding of data flow\")\n",
    "\n",
    "# Define input\n",
    "input_layer = layers.Input(shape=[8], name=\"input\")\n",
    "\n",
    "# Define hidden layers\n",
    "hidden1 = layers.Dense(30, activation=\"relu\", name=\"hidden1\")(input_layer)\n",
    "hidden2 = layers.Dense(30, activation=\"relu\", name=\"hidden2\")(hidden1)\n",
    "\n",
    "# Define output\n",
    "output_layer = layers.Dense(1, name=\"output\")(hidden2)\n",
    "\n",
    "# Create model\n",
    "model_functional = Model(inputs=input_layer, outputs=output_layer, name=\"functional_model\")\n",
    "\n",
    "print(\"\\nüìä Functional Model (Same Architecture as Sequential):\")\n",
    "model_functional.summary()\n",
    "\n",
    "print(\"\\nüîç Key Differences:\")\n",
    "print(\"  ‚Ä¢ Sequential: model = Sequential([layers...])\")\n",
    "print(\"  ‚Ä¢ Functional: define inputs ‚Üí connect layers ‚Üí create Model()\")\n",
    "\n",
    "print(\"\\n‚úÖ Functional API demonstrated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6639b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WIDE & DEEP NETWORK ARCHITECTURE\n",
      "============================================================\n",
      "\n",
      "üèóÔ∏è Wide & Deep Concept:\n",
      "------------------------------------------------------------\n",
      "WIDE PATH:\n",
      "  ‚Ä¢ Short path from input to output\n",
      "  ‚Ä¢ Memorizes patterns directly\n",
      "  ‚Ä¢ Good for simple, sparse features\n",
      "\n",
      "DEEP PATH:\n",
      "  ‚Ä¢ Multiple hidden layers\n",
      "  ‚Ä¢ Learns complex representations\n",
      "  ‚Ä¢ Good for generalization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Wide & Deep Model Architecture:\n",
      "Model: \"wide_deep_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)     [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " deep_hidden1 (Dense)        (None, 30)                   210       ['deep_input[0][0]']          \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)     [(None, 5)]                  0         []                            \n",
      "                                                                                                  \n",
      " deep_hidden2 (Dense)        (None, 30)                   930       ['deep_hidden1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 35)                   0         ['wide_input[0][0]',          \n",
      " )                                                                   'deep_hidden2[0][0]']        \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 1)                    36        ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1176 (4.59 KB)\n",
      "Trainable params: 1176 (4.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "üé® Architecture Diagram:\n",
      "------------------------------------------------------------\n",
      "input_A (5) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "                          ‚îÇ\n",
      "                          ‚îú‚îÄ‚îÄ‚Üí Concatenate ‚îÄ‚îÄ‚Üí Output\n",
      "                          ‚îÇ\n",
      "input_B (6) ‚îÄ‚îÄ‚Üí Dense ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ\n",
      "               ‚Üì\n",
      "              Dense\n",
      "\n",
      "‚úÖ Wide & Deep model created!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 5: Wide & Deep Network\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WIDE & DEEP NETWORK ARCHITECTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüèóÔ∏è Wide & Deep Concept:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"WIDE PATH:\")\n",
    "print(\"  ‚Ä¢ Short path from input to output\")\n",
    "print(\"  ‚Ä¢ Memorizes patterns directly\")\n",
    "print(\"  ‚Ä¢ Good for simple, sparse features\")\n",
    "print(\"\\nDEEP PATH:\")\n",
    "print(\"  ‚Ä¢ Multiple hidden layers\")\n",
    "print(\"  ‚Ä¢ Learns complex representations\")\n",
    "print(\"  ‚Ä¢ Good for generalization\")\n",
    "\n",
    "# Prepare data splits\n",
    "X_train_A = X_train_scaled[:, :5]  # First 5 features for wide\n",
    "X_train_B = X_train_scaled[:, 2:]  # Last 6 features for deep (with overlap)\n",
    "X_valid_A = X_valid_scaled[:, :5]\n",
    "X_valid_B = X_valid_scaled[:, 2:]\n",
    "X_test_A = X_test_scaled[:, :5]\n",
    "X_test_B = X_test_scaled[:, 2:]\n",
    "\n",
    "# Define inputs\n",
    "input_A = layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = layers.Input(shape=[6], name=\"deep_input\")\n",
    "\n",
    "# DEEP PATH\n",
    "hidden1 = layers.Dense(30, activation=\"relu\", name=\"deep_hidden1\")(input_B)\n",
    "hidden2 = layers.Dense(30, activation=\"relu\", name=\"deep_hidden2\")(hidden1)\n",
    "\n",
    "# CONCATENATE wide + deep\n",
    "concat = layers.Concatenate()([input_A, hidden2])\n",
    "\n",
    "# Output layer\n",
    "output = layers.Dense(1, name=\"output\")(concat)\n",
    "\n",
    "# Create model\n",
    "model_wide_deep = Model(inputs=[input_A, input_B], outputs=output, name=\"wide_deep_model\")\n",
    "\n",
    "print(\"\\nüìä Wide & Deep Model Architecture:\")\n",
    "model_wide_deep.summary()\n",
    "\n",
    "# Visualize architecture\n",
    "print(\"\\nüé® Architecture Diagram:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"input_A (5) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"                          ‚îÇ\")\n",
    "print(\"                          ‚îú‚îÄ‚îÄ‚Üí Concatenate ‚îÄ‚îÄ‚Üí Output\")\n",
    "print(\"                          ‚îÇ\")\n",
    "print(\"input_B (6) ‚îÄ‚îÄ‚Üí Dense ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ\")\n",
    "print(\"               ‚Üì\")\n",
    "print(\"              Dense\")\n",
    "\n",
    "print(\"\\n‚úÖ Wide & Deep model created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bb09f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MULTIPLE OUTPUTS MODEL\n",
      "============================================================\n",
      "\n",
      "üéØ Use Case:\n",
      "  ‚Ä¢ Predicting BOTH house price AND category\n",
      "  ‚Ä¢ One model, two tasks (multi-task learning)\n",
      "\n",
      "üìä Multi-Output Model:\n",
      "Model: \"multi_output_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input (InputLayer)          [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " hidden1 (Dense)             (None, 30)                   270       ['input[0][0]']               \n",
      "                                                                                                  \n",
      " hidden2 (Dense)             (None, 30)                   930       ['hidden1[0][0]']             \n",
      "                                                                                                  \n",
      " price (Dense)               (None, 1)                    31        ['hidden2[0][0]']             \n",
      "                                                                                                  \n",
      " category (Dense)            (None, 3)                    93        ['hidden2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1324 (5.17 KB)\n",
      "Trainable params: 1324 (5.17 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "üé® Architecture:\n",
      "------------------------------------------------------------\n",
      "Input (8)\n",
      "  ‚Üì\n",
      "Dense(30) ‚Üí Dense(30)\n",
      "  ‚îú‚îÄ‚îÄ‚Üí Dense(1) ‚Üí Price (regression)\n",
      "  ‚îî‚îÄ‚îÄ‚Üí Dense(3, softmax) ‚Üí Category (classification)\n",
      "\n",
      "‚úÖ Multi-output model created!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 6: Multiple Outputs Model\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MULTIPLE OUTPUTS MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüéØ Use Case:\")\n",
    "print(\"  ‚Ä¢ Predicting BOTH house price AND category\")\n",
    "print(\"  ‚Ä¢ One model, two tasks (multi-task learning)\")\n",
    "\n",
    "# Create synthetic categories (0: cheap, 1: medium, 2: expensive)\n",
    "y_train_cat = np.digitize(y_train, bins=[1.5, 3.0])\n",
    "y_valid_cat = np.digitize(y_valid, bins=[1.5, 3.0])\n",
    "y_test_cat = np.digitize(y_test, bins=[1.5, 3.0])\n",
    "\n",
    "# Define input\n",
    "input_layer = layers.Input(shape=[8], name=\"input\")\n",
    "\n",
    "# Shared hidden layers\n",
    "hidden1 = layers.Dense(30, activation=\"relu\", name=\"hidden1\")(input_layer)\n",
    "hidden2 = layers.Dense(30, activation=\"relu\", name=\"hidden2\")(hidden1)\n",
    "\n",
    "# OUTPUT 1: Regression (price)\n",
    "output_price = layers.Dense(1, name=\"price\")(hidden2)\n",
    "\n",
    "# OUTPUT 2: Classification (category)\n",
    "output_category = layers.Dense(3, activation=\"softmax\", name=\"category\")(hidden2)\n",
    "\n",
    "# Create model with MULTIPLE outputs\n",
    "model_multi_output = Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=[output_price, output_category],\n",
    "    name=\"multi_output_model\"\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Multi-Output Model:\")\n",
    "model_multi_output.summary()\n",
    "\n",
    "print(\"\\nüé® Architecture:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Input (8)\")\n",
    "print(\"  ‚Üì\")\n",
    "print(\"Dense(30) ‚Üí Dense(30)\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ‚Üí Dense(1) ‚Üí Price (regression)\")\n",
    "print(\"  ‚îî‚îÄ‚îÄ‚Üí Dense(3, softmax) ‚Üí Category (classification)\")\n",
    "\n",
    "print(\"\\n‚úÖ Multi-output model created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63597e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING MULTI-OUTPUT MODEL\n",
      "============================================================\n",
      "‚öôÔ∏è Compilation Settings:\n",
      "  Price output: MSE loss + MAE metric\n",
      "  Category output: Sparse CE loss + Accuracy metric\n",
      "\n",
      "üöÄ Training started...\n",
      "Epoch 1/20\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.8480 - price_loss: 0.2589 - category_loss: 0.5891 - price_mae: 0.3107 - category_accuracy: 0.8188 - val_loss: 0.4925 - val_price_loss: 0.0369 - val_category_loss: 0.4555 - val_price_mae: 0.1497 - val_category_accuracy: 0.8359\n",
      "Epoch 2/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.4104 - price_loss: 0.0274 - category_loss: 0.3830 - price_mae: 0.1266 - category_accuracy: 0.8768 - val_loss: 0.3366 - val_price_loss: 0.0196 - val_category_loss: 0.3170 - val_price_mae: 0.1070 - val_category_accuracy: 0.9043\n",
      "Epoch 3/20\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.2995 - price_loss: 0.0175 - category_loss: 0.2820 - price_mae: 0.1023 - category_accuracy: 0.9116 - val_loss: 0.2627 - val_price_loss: 0.0160 - val_category_loss: 0.2468 - val_price_mae: 0.0982 - val_category_accuracy: 0.9180\n",
      "Epoch 4/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.2397 - price_loss: 0.0146 - category_loss: 0.2250 - price_mae: 0.0945 - category_accuracy: 0.9175 - val_loss: 0.2158 - val_price_loss: 0.0137 - val_category_loss: 0.2021 - val_price_mae: 0.0914 - val_category_accuracy: 0.9222\n",
      "Epoch 5/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.1977 - price_loss: 0.0124 - category_loss: 0.1852 - price_mae: 0.0872 - category_accuracy: 0.9228 - val_loss: 0.1819 - val_price_loss: 0.0120 - val_category_loss: 0.1699 - val_price_mae: 0.0859 - val_category_accuracy: 0.9267\n",
      "Epoch 6/20\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.1671 - price_loss: 0.0109 - category_loss: 0.1562 - price_mae: 0.0818 - category_accuracy: 0.9354 - val_loss: 0.1582 - val_price_loss: 0.0109 - val_category_loss: 0.1473 - val_price_mae: 0.0823 - val_category_accuracy: 0.9443\n",
      "Epoch 7/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.1464 - price_loss: 0.0099 - category_loss: 0.1366 - price_mae: 0.0781 - category_accuracy: 0.9453 - val_loss: 0.1423 - val_price_loss: 0.0101 - val_category_loss: 0.1323 - val_price_mae: 0.0794 - val_category_accuracy: 0.9503\n",
      "Epoch 8/20\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.1321 - price_loss: 0.0092 - category_loss: 0.1229 - price_mae: 0.0753 - category_accuracy: 0.9520 - val_loss: 0.1314 - val_price_loss: 0.0094 - val_category_loss: 0.1220 - val_price_mae: 0.0768 - val_category_accuracy: 0.9534\n",
      "Epoch 9/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.1224 - price_loss: 0.0087 - category_loss: 0.1137 - price_mae: 0.0735 - category_accuracy: 0.9564 - val_loss: 0.1227 - val_price_loss: 0.0092 - val_category_loss: 0.1135 - val_price_mae: 0.0765 - val_category_accuracy: 0.9558\n",
      "Epoch 10/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.1156 - price_loss: 0.0084 - category_loss: 0.1072 - price_mae: 0.0722 - category_accuracy: 0.9569 - val_loss: 0.1174 - val_price_loss: 0.0087 - val_category_loss: 0.1087 - val_price_mae: 0.0742 - val_category_accuracy: 0.9573\n",
      "Epoch 11/20\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.1103 - price_loss: 0.0081 - category_loss: 0.1022 - price_mae: 0.0709 - category_accuracy: 0.9593 - val_loss: 0.1132 - val_price_loss: 0.0088 - val_category_loss: 0.1043 - val_price_mae: 0.0748 - val_category_accuracy: 0.9570\n",
      "Epoch 12/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.1063 - price_loss: 0.0080 - category_loss: 0.0983 - price_mae: 0.0702 - category_accuracy: 0.9597 - val_loss: 0.1113 - val_price_loss: 0.0083 - val_category_loss: 0.1030 - val_price_mae: 0.0724 - val_category_accuracy: 0.9573\n",
      "Epoch 13/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.1032 - price_loss: 0.0078 - category_loss: 0.0954 - price_mae: 0.0697 - category_accuracy: 0.9603 - val_loss: 0.1080 - val_price_loss: 0.0082 - val_category_loss: 0.0998 - val_price_mae: 0.0720 - val_category_accuracy: 0.9585\n",
      "Epoch 14/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.1003 - price_loss: 0.0077 - category_loss: 0.0927 - price_mae: 0.0690 - category_accuracy: 0.9630 - val_loss: 0.1060 - val_price_loss: 0.0080 - val_category_loss: 0.0980 - val_price_mae: 0.0710 - val_category_accuracy: 0.9585\n",
      "Epoch 15/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.0984 - price_loss: 0.0076 - category_loss: 0.0908 - price_mae: 0.0686 - category_accuracy: 0.9612 - val_loss: 0.1046 - val_price_loss: 0.0079 - val_category_loss: 0.0967 - val_price_mae: 0.0710 - val_category_accuracy: 0.9585\n",
      "Epoch 16/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.0966 - price_loss: 0.0075 - category_loss: 0.0892 - price_mae: 0.0682 - category_accuracy: 0.9627 - val_loss: 0.1062 - val_price_loss: 0.0079 - val_category_loss: 0.0983 - val_price_mae: 0.0709 - val_category_accuracy: 0.9570\n",
      "Epoch 17/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.0951 - price_loss: 0.0073 - category_loss: 0.0877 - price_mae: 0.0675 - category_accuracy: 0.9619 - val_loss: 0.1039 - val_price_loss: 0.0077 - val_category_loss: 0.0962 - val_price_mae: 0.0702 - val_category_accuracy: 0.9576\n",
      "Epoch 18/20\n",
      "413/413 [==============================] - 1s 1ms/step - loss: 0.0941 - price_loss: 0.0073 - category_loss: 0.0868 - price_mae: 0.0671 - category_accuracy: 0.9624 - val_loss: 0.1034 - val_price_loss: 0.0077 - val_category_loss: 0.0956 - val_price_mae: 0.0699 - val_category_accuracy: 0.9594\n",
      "Epoch 19/20\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.0930 - price_loss: 0.0072 - category_loss: 0.0858 - price_mae: 0.0670 - category_accuracy: 0.9626 - val_loss: 0.1029 - val_price_loss: 0.0084 - val_category_loss: 0.0945 - val_price_mae: 0.0736 - val_category_accuracy: 0.9591\n",
      "Epoch 20/20\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.0923 - price_loss: 0.0071 - category_loss: 0.0852 - price_mae: 0.0667 - category_accuracy: 0.9628 - val_loss: 0.1005 - val_price_loss: 0.0075 - val_category_loss: 0.0930 - val_price_mae: 0.0692 - val_category_accuracy: 0.9594\n",
      "\n",
      "‚úÖ Multi-output training completed!\n",
      "\n",
      "üìà Multi-Output Test Performance:\n",
      "  Price MSE: 0.0072\n",
      "  Price MAE: 0.0673\n",
      "  Category Accuracy: 96.27%\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 7: Training Multi-Output Model\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING MULTI-OUTPUT MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compile with DIFFERENT losses for each output\n",
    "model_multi_output.compile(\n",
    "    loss={\n",
    "        \"price\": \"mse\",\n",
    "        \"category\": \"sparse_categorical_crossentropy\"\n",
    "    },\n",
    "    optimizer=\"sgd\",\n",
    "    metrics={\n",
    "        \"price\": [\"mae\"],\n",
    "        \"category\": [\"accuracy\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚öôÔ∏è Compilation Settings:\")\n",
    "print(\"  Price output: MSE loss + MAE metric\")\n",
    "print(\"  Category output: Sparse CE loss + Accuracy metric\")\n",
    "\n",
    "# Train\n",
    "print(\"\\nüöÄ Training started...\")\n",
    "history_mo = model_multi_output.fit(\n",
    "    X_train_scaled,\n",
    "    {\"price\": y_train, \"category\": y_train_cat},\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid_scaled, {\"price\": y_valid, \"category\": y_valid_cat}),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Multi-output training completed!\")\n",
    "\n",
    "# Evaluate\n",
    "results = model_multi_output.evaluate(\n",
    "    X_test_scaled,\n",
    "    {\"price\": y_test, \"category\": y_test_cat},\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\nüìà Multi-Output Test Performance:\")\n",
    "print(f\"  Price MSE: {results[1]:.4f}\")\n",
    "print(f\"  Price MAE: {results[3]:.4f}\")\n",
    "print(f\"  Category Accuracy: {results[4]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4774411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUBCLASSING API - DYNAMIC MODELS\n",
      "============================================================\n",
      "\n",
      "3Ô∏è‚É£ SUBCLASSING API\n",
      "------------------------------------------------------------\n",
      "‚úÖ Pros:\n",
      "  ‚Ä¢ Maximum flexibility\n",
      "  ‚Ä¢ Dynamic behavior (if/else, loops)\n",
      "  ‚Ä¢ Custom training loops\n",
      "  ‚Ä¢ Research-oriented\n",
      "\n",
      "‚ùå Cons:\n",
      "  ‚Ä¢ Most verbose\n",
      "  ‚Ä¢ Harder to debug\n",
      "  ‚Ä¢ No automatic model.summary()\n",
      "\n",
      "üèóÔ∏è Custom Subclassed Model Created!\n",
      "  ‚Ä¢ Class: WideAndDeepModel\n",
      "  ‚Ä¢ Inherits from: keras.Model\n",
      "  ‚Ä¢ Custom __init__: Define layers\n",
      "  ‚Ä¢ Custom call(): Define forward pass\n",
      "\n",
      "‚ö†Ô∏è NOTE: model.summary() not available automatically!\n",
      "   Need to build the model first with input shape.\n",
      "\n",
      "‚úÖ Subclassing model created!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 8: Subclassing API - Custom Model\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUBCLASSING API - DYNAMIC MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ SUBCLASSING API\")\n",
    "print(\"-\" * 60)\n",
    "print(\"‚úÖ Pros:\")\n",
    "print(\"  ‚Ä¢ Maximum flexibility\")\n",
    "print(\"  ‚Ä¢ Dynamic behavior (if/else, loops)\")\n",
    "print(\"  ‚Ä¢ Custom training loops\")\n",
    "print(\"  ‚Ä¢ Research-oriented\")\n",
    "print(\"\\n‚ùå Cons:\")\n",
    "print(\"  ‚Ä¢ Most verbose\")\n",
    "print(\"  ‚Ä¢ Harder to debug\")\n",
    "print(\"  ‚Ä¢ No automatic model.summary()\")\n",
    "\n",
    "# Define custom model class\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Define layers in __init__\n",
    "        self.hidden1 = layers.Dense(units, activation=activation, name=\"hidden1\")\n",
    "        self.hidden2 = layers.Dense(units, activation=activation, name=\"hidden2\")\n",
    "        self.main_output = layers.Dense(1, name=\"main_output\")\n",
    "        self.aux_output = layers.Dense(1, name=\"aux_output\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass in call()\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "# Instantiate custom model\n",
    "model_subclass = WideAndDeepModel(units=30)\n",
    "\n",
    "print(\"\\nüèóÔ∏è Custom Subclassed Model Created!\")\n",
    "print(\"  ‚Ä¢ Class: WideAndDeepModel\")\n",
    "print(\"  ‚Ä¢ Inherits from: keras.Model\")\n",
    "print(\"  ‚Ä¢ Custom __init__: Define layers\")\n",
    "print(\"  ‚Ä¢ Custom call(): Define forward pass\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è NOTE: model.summary() not available automatically!\")\n",
    "print(\"   Need to build the model first with input shape.\")\n",
    "\n",
    "# Build model\n",
    "model_subclass.build(input_shape=[(None, 5), (None, 6)])\n",
    "\n",
    "print(\"\\n‚úÖ Subclassing model created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "785fc31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING SUBCLASSED MODEL\n",
      "============================================================\n",
      "‚öôÔ∏è Model compiled!\n",
      "\n",
      "üöÄ Training started...\n",
      "‚úÖ Training completed!\n",
      "\n",
      "üìà Subclassed Model Performance:\n",
      "  Number of metrics: 5\n",
      "  Total Loss: 0.2227\n",
      "  Main Output Loss: 0.0067\n",
      "  Aux Output Loss: 0.2160\n",
      "  Main Output MAE: 0.0649\n",
      "  Aux Output MAE: 0.3685\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 9: Training Subclassed Model\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING SUBCLASSED MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compile\n",
    "model_subclass.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "print(\"‚öôÔ∏è Model compiled!\")\n",
    "\n",
    "# Train\n",
    "print(\"\\nüöÄ Training started...\")\n",
    "history_subclass = model_subclass.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train],  # Main and auxiliary outputs\n",
    "    epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]),\n",
    "    verbose=0  # Silent training\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training completed!\")\n",
    "\n",
    "# Evaluate\n",
    "results_subclass = model_subclass.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test], verbose=0\n",
    ")\n",
    "\n",
    "# Print results (check length first)\n",
    "print(f\"\\nüìà Subclassed Model Performance:\")\n",
    "print(f\"  Number of metrics: {len(results_subclass)}\")\n",
    "\n",
    "if len(results_subclass) >= 4:\n",
    "    print(f\"  Total Loss: {results_subclass[0]:.4f}\")\n",
    "    print(f\"  Main Output Loss: {results_subclass[1]:.4f}\")\n",
    "    print(f\"  Aux Output Loss: {results_subclass[2]:.4f}\")\n",
    "    print(f\"  Main Output MAE: {results_subclass[3]:.4f}\")\n",
    "    if len(results_subclass) > 4:\n",
    "        print(f\"  Aux Output MAE: {results_subclass[4]:.4f}\")\n",
    "else:\n",
    "    for i, result in enumerate(results_subclass):\n",
    "        print(f\"  Metric {i}: {result:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46668f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "API COMPARISON SUMMARY\n",
      "============================================================\n",
      "\n",
      "==========================================================================================\n",
      "         Feature    Sequential            Functional              Subclassing\n",
      "     Ease of Use         ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê                  ‚≠ê‚≠ê‚≠ê‚≠ê                      ‚≠ê‚≠ê‚≠ê\n",
      "  Code Verbosity       Minimal              Moderate                  Verbose\n",
      " Multiple Inputs             ‚ùå                     ‚úÖ                        ‚úÖ\n",
      "Multiple Outputs             ‚ùå                     ‚úÖ                        ‚úÖ\n",
      "   Shared Layers             ‚ùå                     ‚úÖ                        ‚úÖ\n",
      "Dynamic Behavior             ‚ùå                     ‚ùå                        ‚úÖ\n",
      " model.summary()             ‚úÖ                     ‚úÖ                ‚ö†Ô∏è Manual\n",
      "        Best For Simple models Complex architectures Research & custom models\n",
      "==========================================================================================\n",
      "\n",
      "üìä DECISION GUIDE:\n",
      "------------------------------------------------------------\n",
      "Use SEQUENTIAL when:\n",
      "  ‚Üí Simple feedforward network\n",
      "  ‚Üí Single input, single output\n",
      "  ‚Üí Linear stack of layers\n",
      "\n",
      "Use FUNCTIONAL when:\n",
      "  ‚Üí Multiple inputs/outputs\n",
      "  ‚Üí Shared layers (e.g., Siamese networks)\n",
      "  ‚Üí Non-sequential topology (skip connections)\n",
      "\n",
      "Use SUBCLASSING when:\n",
      "  ‚Üí Need dynamic behavior (if/else, loops)\n",
      "  ‚Üí Custom training loops\n",
      "  ‚Üí Research & experimentation\n",
      "\n",
      "‚úÖ API comparison completed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 10: API Comparison Summary\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"API COMPARISON SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_data = {\n",
    "    'Feature': [\n",
    "        'Ease of Use',\n",
    "        'Code Verbosity',\n",
    "        'Multiple Inputs',\n",
    "        'Multiple Outputs',\n",
    "        'Shared Layers',\n",
    "        'Dynamic Behavior',\n",
    "        'model.summary()',\n",
    "        'Best For'\n",
    "    ],\n",
    "    'Sequential': [\n",
    "        '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê',\n",
    "        'Minimal',\n",
    "        '‚ùå',\n",
    "        '‚ùå',\n",
    "        '‚ùå',\n",
    "        '‚ùå',\n",
    "        '‚úÖ',\n",
    "        'Simple models'\n",
    "    ],\n",
    "    'Functional': [\n",
    "        '‚≠ê‚≠ê‚≠ê‚≠ê',\n",
    "        'Moderate',\n",
    "        '‚úÖ',\n",
    "        '‚úÖ',\n",
    "        '‚úÖ',\n",
    "        '‚ùå',\n",
    "        '‚úÖ',\n",
    "        'Complex architectures'\n",
    "    ],\n",
    "    'Subclassing': [\n",
    "        '‚≠ê‚≠ê‚≠ê',\n",
    "        'Verbose',\n",
    "        '‚úÖ',\n",
    "        '‚úÖ',\n",
    "        '‚úÖ',\n",
    "        '‚úÖ',\n",
    "        '‚ö†Ô∏è Manual',\n",
    "        'Research & custom models'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(df_comparison.to_string(index=False))\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(\"\\nüìä DECISION GUIDE:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Use SEQUENTIAL when:\")\n",
    "print(\"  ‚Üí Simple feedforward network\")\n",
    "print(\"  ‚Üí Single input, single output\")\n",
    "print(\"  ‚Üí Linear stack of layers\")\n",
    "\n",
    "print(\"\\nUse FUNCTIONAL when:\")\n",
    "print(\"  ‚Üí Multiple inputs/outputs\")\n",
    "print(\"  ‚Üí Shared layers (e.g., Siamese networks)\")\n",
    "print(\"  ‚Üí Non-sequential topology (skip connections)\")\n",
    "\n",
    "print(\"\\nUse SUBCLASSING when:\")\n",
    "print(\"  ‚Üí Need dynamic behavior (if/else, loops)\")\n",
    "print(\"  ‚Üí Custom training loops\")\n",
    "print(\"  ‚Üí Research & experimentation\")\n",
    "\n",
    "print(\"\\n‚úÖ API comparison completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d1a5f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING & LOADING MODELS\n",
      "============================================================\n",
      "‚úÖ Functional model saved: functional_model.keras\n",
      "‚úÖ Wide & Deep model saved: wide_deep_model.keras\n",
      "\n",
      "‚úÖ Model loaded successfully!\n",
      "‚úÖ Loaded model compiled!\n",
      "\n",
      "üìä Loaded Model Performance:\n",
      "  Test Loss (MSE): 7.0759\n",
      "  Test MAE: 2.6063\n",
      "\n",
      "üíæ Saving Formats:\n",
      "------------------------------------------------------------\n",
      "1. KERAS FORMAT (.keras) - RECOMMENDED ‚≠ê\n",
      "   ‚Ä¢ Native Keras format\n",
      "   ‚Ä¢ Saves architecture + weights + optimizer state\n",
      "   ‚Ä¢ Usage: model.save('model.keras')\n",
      "\n",
      "2. H5 FORMAT (.h5) - LEGACY\n",
      "   ‚Ä¢ HDF5 format\n",
      "   ‚Ä¢ Larger file size\n",
      "   ‚Ä¢ Usage: model.save('model.h5')\n",
      "\n",
      "3. SAVEDMODEL FORMAT (directory)\n",
      "   ‚Ä¢ TensorFlow SavedModel\n",
      "   ‚Ä¢ For TensorFlow Serving\n",
      "   ‚Ä¢ Usage: model.save('my_model')\n",
      "\n",
      "‚ö†Ô∏è IMPORTANT NOTE:\n",
      "  When loading models, you may need to re-compile them\n",
      "  if optimizer state is not preserved!\n",
      "\n",
      "‚úÖ Model saving demonstrated!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 11: Saving & Loading Models\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING & LOADING MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save functional model\n",
    "model_functional.save(\"functional_model.keras\")\n",
    "print(\"‚úÖ Functional model saved: functional_model.keras\")\n",
    "\n",
    "# Save wide & deep model\n",
    "model_wide_deep.save(\"wide_deep_model.keras\")\n",
    "print(\"‚úÖ Wide & Deep model saved: wide_deep_model.keras\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = keras.models.load_model(\"functional_model.keras\")\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# Compile loaded model (IMPORTANT!)\n",
    "loaded_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "print(\"‚úÖ Loaded model compiled!\")\n",
    "\n",
    "# Verify loaded model\n",
    "test_loss, test_mae = loaded_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"\\nüìä Loaded Model Performance:\")\n",
    "print(f\"  Test Loss (MSE): {test_loss:.4f}\")\n",
    "print(f\"  Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "print(\"\\nüíæ Saving Formats:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"1. KERAS FORMAT (.keras) - RECOMMENDED ‚≠ê\")\n",
    "print(\"   ‚Ä¢ Native Keras format\")\n",
    "print(\"   ‚Ä¢ Saves architecture + weights + optimizer state\")\n",
    "print(\"   ‚Ä¢ Usage: model.save('model.keras')\")\n",
    "\n",
    "print(\"\\n2. H5 FORMAT (.h5) - LEGACY\")\n",
    "print(\"   ‚Ä¢ HDF5 format\")\n",
    "print(\"   ‚Ä¢ Larger file size\")\n",
    "print(\"   ‚Ä¢ Usage: model.save('model.h5')\")\n",
    "\n",
    "print(\"\\n3. SAVEDMODEL FORMAT (directory)\")\n",
    "print(\"   ‚Ä¢ TensorFlow SavedModel\")\n",
    "print(\"   ‚Ä¢ For TensorFlow Serving\")\n",
    "print(\"   ‚Ä¢ Usage: model.save('my_model')\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANT NOTE:\")\n",
    "print(\"  When loading models, you may need to re-compile them\")\n",
    "print(\"  if optimizer state is not preserved!\")\n",
    "\n",
    "print(\"\\n‚úÖ Model saving demonstrated!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
