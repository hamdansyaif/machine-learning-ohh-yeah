{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ca38c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\fraud_ml\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "============================================================\n",
      "CALLBACKS & TENSORBOARD\n",
      "============================================================\n",
      "TensorFlow version: 2.15.0\n",
      "\n",
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 1: Import Libraries & Setup\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow & Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CALLBACKS & TENSORBOARD\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(\"\\n‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92b32dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA PREPARATION - FASHION MNIST\n",
      "============================================================\n",
      "\n",
      "üìä Data Split:\n",
      "  Training: 55,000 samples\n",
      "  Validation: 5,000 samples\n",
      "  Test: 10,000 samples\n",
      "\n",
      "‚úÖ Data preparation completed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 2: Load & Prepare Fashion MNIST\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA PREPARATION - FASHION MNIST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load Fashion MNIST\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Split validation set\n",
    "X_valid, y_valid = X_train_full[:5000], y_train_full[:5000]\n",
    "X_train, y_train = X_train_full[5000:], y_train_full[5000:]\n",
    "\n",
    "# Scale pixel values\n",
    "X_train = X_train / 255.0\n",
    "X_valid = X_valid / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(f\"\\nüìä Data Split:\")\n",
    "print(f\"  Training: {X_train.shape[0]:,} samples\")\n",
    "print(f\"  Validation: {X_valid.shape[0]:,} samples\")\n",
    "print(f\"  Test: {X_test.shape[0]:,} samples\")\n",
    "\n",
    "print(\"\\n‚úÖ Data preparation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f784a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODELCHECKPOINT CALLBACK\n",
      "============================================================\n",
      "\n",
      "üìå ModelCheckpoint Purpose:\n",
      "  ‚Ä¢ Automatically save model during training\n",
      "  ‚Ä¢ Save only when model improves\n",
      "  ‚Ä¢ Prevent losing best model if training diverges\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\fraud_ml\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\fraud_ml\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "\n",
      "‚öôÔ∏è ModelCheckpoint Settings:\n",
      "  Filepath: models/best_model.keras\n",
      "  Monitor: val_loss\n",
      "  Save best only: True\n",
      "\n",
      "üöÄ Training with ModelCheckpoint...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\fraud_ml\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\fraud_ml\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1691/1719 [============================>.] - ETA: 0s - loss: 0.7194 - accuracy: 0.7641\n",
      "Epoch 1: val_loss improved from inf to 0.52283, saving model to models\\best_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7159 - accuracy: 0.7653 - val_loss: 0.5228 - val_accuracy: 0.8218\n",
      "Epoch 2/10\n",
      "1698/1719 [============================>.] - ETA: 0s - loss: 0.4886 - accuracy: 0.8287\n",
      "Epoch 2: val_loss improved from 0.52283 to 0.43724, saving model to models\\best_model.keras\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4883 - accuracy: 0.8289 - val_loss: 0.4372 - val_accuracy: 0.8520\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.8442\n",
      "Epoch 3: val_loss did not improve from 0.43724\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4429 - accuracy: 0.8442 - val_loss: 0.5286 - val_accuracy: 0.8026\n",
      "Epoch 4/10\n",
      "1689/1719 [============================>.] - ETA: 0s - loss: 0.4162 - accuracy: 0.8545\n",
      "Epoch 4: val_loss improved from 0.43724 to 0.39417, saving model to models\\best_model.keras\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4160 - accuracy: 0.8545 - val_loss: 0.3942 - val_accuracy: 0.8652\n",
      "Epoch 5/10\n",
      "1692/1719 [============================>.] - ETA: 0s - loss: 0.3971 - accuracy: 0.8616\n",
      "Epoch 5: val_loss improved from 0.39417 to 0.37684, saving model to models\\best_model.keras\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3971 - accuracy: 0.8615 - val_loss: 0.3768 - val_accuracy: 0.8684\n",
      "Epoch 6/10\n",
      "1703/1719 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8673\n",
      "Epoch 6: val_loss improved from 0.37684 to 0.37284, saving model to models\\best_model.keras\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3780 - accuracy: 0.8674 - val_loss: 0.3728 - val_accuracy: 0.8724\n",
      "Epoch 7/10\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 0.3652 - accuracy: 0.8718\n",
      "Epoch 7: val_loss improved from 0.37284 to 0.36255, saving model to models\\best_model.keras\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3653 - accuracy: 0.8718 - val_loss: 0.3626 - val_accuracy: 0.8754\n",
      "Epoch 8/10\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 0.3539 - accuracy: 0.8752\n",
      "Epoch 8: val_loss did not improve from 0.36255\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3540 - accuracy: 0.8752 - val_loss: 0.3846 - val_accuracy: 0.8626\n",
      "Epoch 9/10\n",
      "1688/1719 [============================>.] - ETA: 0s - loss: 0.3430 - accuracy: 0.8786\n",
      "Epoch 9: val_loss improved from 0.36255 to 0.34994, saving model to models\\best_model.keras\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3426 - accuracy: 0.8788 - val_loss: 0.3499 - val_accuracy: 0.8738\n",
      "Epoch 10/10\n",
      "1692/1719 [============================>.] - ETA: 0s - loss: 0.3343 - accuracy: 0.8813\n",
      "Epoch 10: val_loss improved from 0.34994 to 0.34721, saving model to models\\best_model.keras\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3338 - accuracy: 0.8815 - val_loss: 0.3472 - val_accuracy: 0.8800\n",
      "\n",
      "‚úÖ Training with ModelCheckpoint completed!\n",
      "‚úÖ Best model saved at: models/best_model.keras\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 3: ModelCheckpoint - Save Best Model\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODELCHECKPOINT CALLBACK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìå ModelCheckpoint Purpose:\")\n",
    "print(\"  ‚Ä¢ Automatically save model during training\")\n",
    "print(\"  ‚Ä¢ Save only when model improves\")\n",
    "print(\"  ‚Ä¢ Prevent losing best model if training diverges\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Build model\n",
    "model_checkpoint = keras.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_checkpoint.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create ModelCheckpoint callback\n",
    "checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "    filepath=\"models/best_model.keras\",\n",
    "    save_best_only=True,  # Only save when val_loss improves\n",
    "    monitor=\"val_loss\",    # Metric to monitor\n",
    "    verbose=1              # Print message when saving\n",
    ")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è ModelCheckpoint Settings:\")\n",
    "print(f\"  Filepath: models/best_model.keras\")\n",
    "print(f\"  Monitor: val_loss\")\n",
    "print(f\"  Save best only: True\")\n",
    "\n",
    "# Train with checkpoint\n",
    "print(\"\\nüöÄ Training with ModelCheckpoint...\")\n",
    "history_cp = model_checkpoint.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[checkpoint_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training with ModelCheckpoint completed!\")\n",
    "print(f\"‚úÖ Best model saved at: models/best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064392cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EARLYSTOPPING CALLBACK\n",
      "============================================================\n",
      "\n",
      "üìå EarlyStopping Purpose:\n",
      "  ‚Ä¢ Stop training when validation metric stops improving\n",
      "  ‚Ä¢ Prevent overfitting\n",
      "  ‚Ä¢ Save time (no need to train 100 epochs)\n",
      "\n",
      "‚öôÔ∏è EarlyStopping Settings:\n",
      "  Monitor: val_loss\n",
      "  Patience: 5 epochs\n",
      "  Restore best weights: True\n",
      "\n",
      "üöÄ Training with EarlyStopping (max 50 epochs)...\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7223 - accuracy: 0.7601 - val_loss: 0.5278 - val_accuracy: 0.8198\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4896 - accuracy: 0.8288 - val_loss: 0.4393 - val_accuracy: 0.8520\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4430 - accuracy: 0.8443 - val_loss: 0.5397 - val_accuracy: 0.7946\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4157 - accuracy: 0.8551 - val_loss: 0.3964 - val_accuracy: 0.8662\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3965 - accuracy: 0.8611 - val_loss: 0.3786 - val_accuracy: 0.8676\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3778 - accuracy: 0.8661 - val_loss: 0.3741 - val_accuracy: 0.8726\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3647 - accuracy: 0.8713 - val_loss: 0.3662 - val_accuracy: 0.8748\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3535 - accuracy: 0.8751 - val_loss: 0.3851 - val_accuracy: 0.8644\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3429 - accuracy: 0.8795 - val_loss: 0.3541 - val_accuracy: 0.8728\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3339 - accuracy: 0.8811 - val_loss: 0.3503 - val_accuracy: 0.8748\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3256 - accuracy: 0.8830 - val_loss: 0.3475 - val_accuracy: 0.8780\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3168 - accuracy: 0.8857 - val_loss: 0.3352 - val_accuracy: 0.8796\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3101 - accuracy: 0.8893 - val_loss: 0.3321 - val_accuracy: 0.8844\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3039 - accuracy: 0.8909 - val_loss: 0.3373 - val_accuracy: 0.8768\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2958 - accuracy: 0.8933 - val_loss: 0.3271 - val_accuracy: 0.8796\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2907 - accuracy: 0.8949 - val_loss: 0.3110 - val_accuracy: 0.8884\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2854 - accuracy: 0.8978 - val_loss: 0.3593 - val_accuracy: 0.8708\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2790 - accuracy: 0.8991 - val_loss: 0.3236 - val_accuracy: 0.8882\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2740 - accuracy: 0.9011 - val_loss: 0.3141 - val_accuracy: 0.8898\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2684 - accuracy: 0.9034 - val_loss: 0.3234 - val_accuracy: 0.8812\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2630 - accuracy: 0.9051 - val_loss: 0.3043 - val_accuracy: 0.8896\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2585 - accuracy: 0.9064 - val_loss: 0.2978 - val_accuracy: 0.8966\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2540 - accuracy: 0.9087 - val_loss: 0.2998 - val_accuracy: 0.8944\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2497 - accuracy: 0.9098 - val_loss: 0.3057 - val_accuracy: 0.8872\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2451 - accuracy: 0.9115 - val_loss: 0.2976 - val_accuracy: 0.8968\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2406 - accuracy: 0.9137 - val_loss: 0.3046 - val_accuracy: 0.8896\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2371 - accuracy: 0.9153 - val_loss: 0.2952 - val_accuracy: 0.8952\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2337 - accuracy: 0.9156 - val_loss: 0.2980 - val_accuracy: 0.8924\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2292 - accuracy: 0.9182 - val_loss: 0.3084 - val_accuracy: 0.8860\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2259 - accuracy: 0.9201 - val_loss: 0.3054 - val_accuracy: 0.8910\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2216 - accuracy: 0.9202 - val_loss: 0.2965 - val_accuracy: 0.8932\n",
      "Epoch 32/50\n",
      "1697/1719 [============================>.] - ETA: 0s - loss: 0.2186 - accuracy: 0.9219Restoring model weights from the end of the best epoch: 27.\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2184 - accuracy: 0.9220 - val_loss: 0.3050 - val_accuracy: 0.8908\n",
      "Epoch 32: early stopping\n",
      "\n",
      "‚úÖ Training stopped at epoch 32\n",
      "‚úÖ Best weights restored!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 4: EarlyStopping - Prevent Overfitting\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EARLYSTOPPING CALLBACK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìå EarlyStopping Purpose:\")\n",
    "print(\"  ‚Ä¢ Stop training when validation metric stops improving\")\n",
    "print(\"  ‚Ä¢ Prevent overfitting\")\n",
    "print(\"  ‚Ä¢ Save time (no need to train 100 epochs)\")\n",
    "\n",
    "# Build new model\n",
    "model_early = keras.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_early.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create EarlyStopping callback\n",
    "early_stopping_cb = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,           # Stop after 5 epochs without improvement\n",
    "    restore_best_weights=True,  # Restore best weights\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è EarlyStopping Settings:\")\n",
    "print(f\"  Monitor: val_loss\")\n",
    "print(f\"  Patience: 5 epochs\")\n",
    "print(f\"  Restore best weights: True\")\n",
    "\n",
    "# Train with early stopping\n",
    "print(\"\\nüöÄ Training with EarlyStopping (max 50 epochs)...\")\n",
    "history_es = model_early.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,  # Set high, but will stop early\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Training stopped at epoch {len(history_es.history['loss'])}\")\n",
    "print(\"‚úÖ Best weights restored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95767c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMBINING MULTIPLE CALLBACKS\n",
      "============================================================\n",
      "\n",
      "üìå Best Practice:\n",
      "  ‚Ä¢ Use BOTH ModelCheckpoint + EarlyStopping\n",
      "  ‚Ä¢ Checkpoint saves best model\n",
      "  ‚Ä¢ EarlyStopping prevents wasted training time\n",
      "\n",
      "‚öôÔ∏è Combined Callbacks:\n",
      "  1. ModelCheckpoint:\n",
      "     - Monitor: val_accuracy (max)\n",
      "     - Save best only: True\n",
      "\n",
      "  2. EarlyStopping:\n",
      "     - Monitor: val_accuracy (max)\n",
      "     - Patience: 10 epochs\n",
      "\n",
      "üöÄ Training with combined callbacks...\n",
      "Epoch 1/100\n",
      "1700/1719 [============================>.] - ETA: 0s - loss: 0.8401 - accuracy: 0.7141\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82160, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8376 - accuracy: 0.7150 - val_loss: 0.5224 - val_accuracy: 0.8216\n",
      "Epoch 2/100\n",
      "1709/1719 [============================>.] - ETA: 0s - loss: 0.5641 - accuracy: 0.8067\n",
      "Epoch 2: val_accuracy improved from 0.82160 to 0.84760, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5639 - accuracy: 0.8069 - val_loss: 0.4504 - val_accuracy: 0.8476\n",
      "Epoch 3/100\n",
      "1707/1719 [============================>.] - ETA: 0s - loss: 0.4995 - accuracy: 0.8259\n",
      "Epoch 3: val_accuracy improved from 0.84760 to 0.85180, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4991 - accuracy: 0.8260 - val_loss: 0.4238 - val_accuracy: 0.8518\n",
      "Epoch 4/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 0.4626 - accuracy: 0.8373\n",
      "Epoch 4: val_accuracy improved from 0.85180 to 0.86380, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4625 - accuracy: 0.8374 - val_loss: 0.3957 - val_accuracy: 0.8638\n",
      "Epoch 5/100\n",
      "1700/1719 [============================>.] - ETA: 0s - loss: 0.4386 - accuracy: 0.8470\n",
      "Epoch 5: val_accuracy improved from 0.86380 to 0.86740, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4384 - accuracy: 0.8469 - val_loss: 0.3757 - val_accuracy: 0.8674\n",
      "Epoch 6/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 0.4180 - accuracy: 0.8527\n",
      "Epoch 6: val_accuracy improved from 0.86740 to 0.87020, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4179 - accuracy: 0.8527 - val_loss: 0.3696 - val_accuracy: 0.8702\n",
      "Epoch 7/100\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 0.4050 - accuracy: 0.8558\n",
      "Epoch 7: val_accuracy improved from 0.87020 to 0.87220, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4049 - accuracy: 0.8558 - val_loss: 0.3571 - val_accuracy: 0.8722\n",
      "Epoch 8/100\n",
      "1697/1719 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.8616\n",
      "Epoch 8: val_accuracy improved from 0.87220 to 0.87680, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3915 - accuracy: 0.8613 - val_loss: 0.3544 - val_accuracy: 0.8768\n",
      "Epoch 9/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8636\n",
      "Epoch 9: val_accuracy did not improve from 0.87680\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3834 - accuracy: 0.8636 - val_loss: 0.3448 - val_accuracy: 0.8760\n",
      "Epoch 10/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 0.3733 - accuracy: 0.8676\n",
      "Epoch 10: val_accuracy improved from 0.87680 to 0.88200, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3731 - accuracy: 0.8677 - val_loss: 0.3406 - val_accuracy: 0.8820\n",
      "Epoch 11/100\n",
      "1709/1719 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.8690\n",
      "Epoch 11: val_accuracy did not improve from 0.88200\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3645 - accuracy: 0.8691 - val_loss: 0.3353 - val_accuracy: 0.8810\n",
      "Epoch 12/100\n",
      "1699/1719 [============================>.] - ETA: 0s - loss: 0.3559 - accuracy: 0.8719\n",
      "Epoch 12: val_accuracy did not improve from 0.88200\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3561 - accuracy: 0.8718 - val_loss: 0.3321 - val_accuracy: 0.8806\n",
      "Epoch 13/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 0.3515 - accuracy: 0.8741\n",
      "Epoch 13: val_accuracy improved from 0.88200 to 0.88480, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3519 - accuracy: 0.8739 - val_loss: 0.3263 - val_accuracy: 0.8848\n",
      "Epoch 14/100\n",
      "1703/1719 [============================>.] - ETA: 0s - loss: 0.3449 - accuracy: 0.8764\n",
      "Epoch 14: val_accuracy did not improve from 0.88480\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3456 - accuracy: 0.8761 - val_loss: 0.3284 - val_accuracy: 0.8808\n",
      "Epoch 15/100\n",
      "1700/1719 [============================>.] - ETA: 0s - loss: 0.3379 - accuracy: 0.8774\n",
      "Epoch 15: val_accuracy did not improve from 0.88480\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3379 - accuracy: 0.8775 - val_loss: 0.3175 - val_accuracy: 0.8842\n",
      "Epoch 16/100\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.8802\n",
      "Epoch 16: val_accuracy improved from 0.88480 to 0.88680, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3331 - accuracy: 0.8802 - val_loss: 0.3140 - val_accuracy: 0.8868\n",
      "Epoch 17/100\n",
      "1707/1719 [============================>.] - ETA: 0s - loss: 0.3259 - accuracy: 0.8825\n",
      "Epoch 17: val_accuracy did not improve from 0.88680\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3258 - accuracy: 0.8827 - val_loss: 0.3218 - val_accuracy: 0.8794\n",
      "Epoch 18/100\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8842\n",
      "Epoch 18: val_accuracy did not improve from 0.88680\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3209 - accuracy: 0.8843 - val_loss: 0.3168 - val_accuracy: 0.8838\n",
      "Epoch 19/100\n",
      "1698/1719 [============================>.] - ETA: 0s - loss: 0.3172 - accuracy: 0.8856\n",
      "Epoch 19: val_accuracy improved from 0.88680 to 0.88940, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3176 - accuracy: 0.8857 - val_loss: 0.3098 - val_accuracy: 0.8894\n",
      "Epoch 20/100\n",
      "1705/1719 [============================>.] - ETA: 0s - loss: 0.3119 - accuracy: 0.8863\n",
      "Epoch 20: val_accuracy did not improve from 0.88940\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3122 - accuracy: 0.8861 - val_loss: 0.3122 - val_accuracy: 0.8874\n",
      "Epoch 21/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 0.3080 - accuracy: 0.8897\n",
      "Epoch 21: val_accuracy improved from 0.88940 to 0.89140, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3078 - accuracy: 0.8897 - val_loss: 0.3035 - val_accuracy: 0.8914\n",
      "Epoch 22/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 0.3043 - accuracy: 0.8903\n",
      "Epoch 22: val_accuracy did not improve from 0.89140\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3042 - accuracy: 0.8903 - val_loss: 0.3049 - val_accuracy: 0.8884\n",
      "Epoch 23/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.8909\n",
      "Epoch 23: val_accuracy improved from 0.89140 to 0.89240, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3010 - accuracy: 0.8908 - val_loss: 0.2997 - val_accuracy: 0.8924\n",
      "Epoch 24/100\n",
      "1699/1719 [============================>.] - ETA: 0s - loss: 0.2948 - accuracy: 0.8923\n",
      "Epoch 24: val_accuracy did not improve from 0.89240\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2951 - accuracy: 0.8922 - val_loss: 0.3009 - val_accuracy: 0.8876\n",
      "Epoch 25/100\n",
      "1709/1719 [============================>.] - ETA: 0s - loss: 0.2905 - accuracy: 0.8964\n",
      "Epoch 25: val_accuracy did not improve from 0.89240\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2906 - accuracy: 0.8964 - val_loss: 0.3006 - val_accuracy: 0.8902\n",
      "Epoch 26/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 0.2879 - accuracy: 0.8966\n",
      "Epoch 26: val_accuracy did not improve from 0.89240\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2878 - accuracy: 0.8966 - val_loss: 0.2939 - val_accuracy: 0.8910\n",
      "Epoch 27/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 0.2851 - accuracy: 0.8964\n",
      "Epoch 27: val_accuracy improved from 0.89240 to 0.89260, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2853 - accuracy: 0.8964 - val_loss: 0.2950 - val_accuracy: 0.8926\n",
      "Epoch 28/100\n",
      "1702/1719 [============================>.] - ETA: 0s - loss: 0.2835 - accuracy: 0.8973\n",
      "Epoch 28: val_accuracy did not improve from 0.89260\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2836 - accuracy: 0.8973 - val_loss: 0.2976 - val_accuracy: 0.8880\n",
      "Epoch 29/100\n",
      "1701/1719 [============================>.] - ETA: 0s - loss: 0.2784 - accuracy: 0.8993\n",
      "Epoch 29: val_accuracy improved from 0.89260 to 0.89280, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2781 - accuracy: 0.8993 - val_loss: 0.2957 - val_accuracy: 0.8928\n",
      "Epoch 30/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 0.2742 - accuracy: 0.8999\n",
      "Epoch 30: val_accuracy did not improve from 0.89280\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2742 - accuracy: 0.8999 - val_loss: 0.2995 - val_accuracy: 0.8892\n",
      "Epoch 31/100\n",
      "1704/1719 [============================>.] - ETA: 0s - loss: 0.2729 - accuracy: 0.9010\n",
      "Epoch 31: val_accuracy improved from 0.89280 to 0.89560, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2732 - accuracy: 0.9008 - val_loss: 0.2896 - val_accuracy: 0.8956\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.9026\n",
      "Epoch 32: val_accuracy did not improve from 0.89560\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2705 - accuracy: 0.9026 - val_loss: 0.2929 - val_accuracy: 0.8930\n",
      "Epoch 33/100\n",
      "1696/1719 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9031\n",
      "Epoch 33: val_accuracy did not improve from 0.89560\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2667 - accuracy: 0.9029 - val_loss: 0.2929 - val_accuracy: 0.8926\n",
      "Epoch 34/100\n",
      "1705/1719 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9030\n",
      "Epoch 34: val_accuracy did not improve from 0.89560\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2646 - accuracy: 0.9031 - val_loss: 0.2940 - val_accuracy: 0.8922\n",
      "Epoch 35/100\n",
      "1708/1719 [============================>.] - ETA: 0s - loss: 0.2607 - accuracy: 0.9047\n",
      "Epoch 35: val_accuracy did not improve from 0.89560\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2608 - accuracy: 0.9047 - val_loss: 0.2843 - val_accuracy: 0.8956\n",
      "Epoch 36/100\n",
      "1711/1719 [============================>.] - ETA: 0s - loss: 0.2581 - accuracy: 0.9061\n",
      "Epoch 36: val_accuracy did not improve from 0.89560\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2581 - accuracy: 0.9061 - val_loss: 0.2913 - val_accuracy: 0.8934\n",
      "Epoch 37/100\n",
      "1708/1719 [============================>.] - ETA: 0s - loss: 0.2534 - accuracy: 0.9074\n",
      "Epoch 37: val_accuracy improved from 0.89560 to 0.89620, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2536 - accuracy: 0.9074 - val_loss: 0.2862 - val_accuracy: 0.8962\n",
      "Epoch 38/100\n",
      "1700/1719 [============================>.] - ETA: 0s - loss: 0.2546 - accuracy: 0.9075\n",
      "Epoch 38: val_accuracy did not improve from 0.89620\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2553 - accuracy: 0.9073 - val_loss: 0.2815 - val_accuracy: 0.8956\n",
      "Epoch 39/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.9102\n",
      "Epoch 39: val_accuracy improved from 0.89620 to 0.89880, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2491 - accuracy: 0.9102 - val_loss: 0.2865 - val_accuracy: 0.8988\n",
      "Epoch 40/100\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 0.2475 - accuracy: 0.9096\n",
      "Epoch 40: val_accuracy did not improve from 0.89880\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2475 - accuracy: 0.9096 - val_loss: 0.2816 - val_accuracy: 0.8988\n",
      "Epoch 41/100\n",
      "1703/1719 [============================>.] - ETA: 0s - loss: 0.2453 - accuracy: 0.9095\n",
      "Epoch 41: val_accuracy did not improve from 0.89880\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2459 - accuracy: 0.9095 - val_loss: 0.2782 - val_accuracy: 0.8970\n",
      "Epoch 42/100\n",
      "1697/1719 [============================>.] - ETA: 0s - loss: 0.2435 - accuracy: 0.9109\n",
      "Epoch 42: val_accuracy did not improve from 0.89880\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2430 - accuracy: 0.9111 - val_loss: 0.2792 - val_accuracy: 0.8964\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.9111\n",
      "Epoch 43: val_accuracy did not improve from 0.89880\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2407 - accuracy: 0.9111 - val_loss: 0.2821 - val_accuracy: 0.8944\n",
      "Epoch 44/100\n",
      "1708/1719 [============================>.] - ETA: 0s - loss: 0.2377 - accuracy: 0.9134\n",
      "Epoch 44: val_accuracy did not improve from 0.89880\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2376 - accuracy: 0.9134 - val_loss: 0.2839 - val_accuracy: 0.8962\n",
      "Epoch 45/100\n",
      "1704/1719 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.9143\n",
      "Epoch 45: val_accuracy did not improve from 0.89880\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2368 - accuracy: 0.9140 - val_loss: 0.2797 - val_accuracy: 0.8958\n",
      "Epoch 46/100\n",
      "1697/1719 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.9142\n",
      "Epoch 46: val_accuracy did not improve from 0.89880\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2339 - accuracy: 0.9142 - val_loss: 0.2859 - val_accuracy: 0.8956\n",
      "Epoch 47/100\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 0.2313 - accuracy: 0.9155\n",
      "Epoch 47: val_accuracy improved from 0.89880 to 0.90000, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2316 - accuracy: 0.9154 - val_loss: 0.2815 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9156\n",
      "Epoch 48: val_accuracy did not improve from 0.90000\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2294 - accuracy: 0.9157 - val_loss: 0.2861 - val_accuracy: 0.8964\n",
      "Epoch 49/100\n",
      "1707/1719 [============================>.] - ETA: 0s - loss: 0.2258 - accuracy: 0.9168\n",
      "Epoch 49: val_accuracy did not improve from 0.90000\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2259 - accuracy: 0.9169 - val_loss: 0.2764 - val_accuracy: 0.8994\n",
      "Epoch 50/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.9172\n",
      "Epoch 50: val_accuracy did not improve from 0.90000\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2243 - accuracy: 0.9172 - val_loss: 0.2805 - val_accuracy: 0.8962\n",
      "Epoch 51/100\n",
      "1707/1719 [============================>.] - ETA: 0s - loss: 0.2217 - accuracy: 0.9190\n",
      "Epoch 51: val_accuracy did not improve from 0.90000\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2220 - accuracy: 0.9189 - val_loss: 0.2815 - val_accuracy: 0.8988\n",
      "Epoch 52/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 0.2206 - accuracy: 0.9196\n",
      "Epoch 52: val_accuracy did not improve from 0.90000\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2206 - accuracy: 0.9196 - val_loss: 0.2838 - val_accuracy: 0.8996\n",
      "Epoch 53/100\n",
      "1700/1719 [============================>.] - ETA: 0s - loss: 0.2211 - accuracy: 0.9187\n",
      "Epoch 53: val_accuracy did not improve from 0.90000\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2210 - accuracy: 0.9189 - val_loss: 0.2856 - val_accuracy: 0.8948\n",
      "Epoch 54/100\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 0.2178 - accuracy: 0.9199\n",
      "Epoch 54: val_accuracy improved from 0.90000 to 0.90140, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2176 - accuracy: 0.9199 - val_loss: 0.2723 - val_accuracy: 0.9014\n",
      "Epoch 55/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9213\n",
      "Epoch 55: val_accuracy did not improve from 0.90140\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2161 - accuracy: 0.9212 - val_loss: 0.2830 - val_accuracy: 0.8972\n",
      "Epoch 56/100\n",
      "1705/1719 [============================>.] - ETA: 0s - loss: 0.2130 - accuracy: 0.9226\n",
      "Epoch 56: val_accuracy did not improve from 0.90140\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2132 - accuracy: 0.9225 - val_loss: 0.2784 - val_accuracy: 0.8998\n",
      "Epoch 57/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.9228\n",
      "Epoch 57: val_accuracy did not improve from 0.90140\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2122 - accuracy: 0.9228 - val_loss: 0.2774 - val_accuracy: 0.9000\n",
      "Epoch 58/100\n",
      "1708/1719 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.9221\n",
      "Epoch 58: val_accuracy did not improve from 0.90140\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2101 - accuracy: 0.9221 - val_loss: 0.2777 - val_accuracy: 0.9014\n",
      "Epoch 59/100\n",
      "1699/1719 [============================>.] - ETA: 0s - loss: 0.2084 - accuracy: 0.9221\n",
      "Epoch 59: val_accuracy did not improve from 0.90140\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2082 - accuracy: 0.9222 - val_loss: 0.2814 - val_accuracy: 0.9010\n",
      "Epoch 60/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9248\n",
      "Epoch 60: val_accuracy did not improve from 0.90140\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2053 - accuracy: 0.9247 - val_loss: 0.2819 - val_accuracy: 0.8986\n",
      "Epoch 61/100\n",
      "1697/1719 [============================>.] - ETA: 0s - loss: 0.2037 - accuracy: 0.9241\n",
      "Epoch 61: val_accuracy did not improve from 0.90140\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2036 - accuracy: 0.9242 - val_loss: 0.2777 - val_accuracy: 0.8988\n",
      "Epoch 62/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 0.2026 - accuracy: 0.9254\n",
      "Epoch 62: val_accuracy did not improve from 0.90140\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2027 - accuracy: 0.9254 - val_loss: 0.2775 - val_accuracy: 0.8992\n",
      "Epoch 63/100\n",
      "1699/1719 [============================>.] - ETA: 0s - loss: 0.2015 - accuracy: 0.9270\n",
      "Epoch 63: val_accuracy improved from 0.90140 to 0.90300, saving model to models\\best_combined_model.keras\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2014 - accuracy: 0.9271 - val_loss: 0.2707 - val_accuracy: 0.9030\n",
      "Epoch 64/100\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9271\n",
      "Epoch 64: val_accuracy did not improve from 0.90300\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1982 - accuracy: 0.9271 - val_loss: 0.2730 - val_accuracy: 0.9006\n",
      "Epoch 65/100\n",
      "1701/1719 [============================>.] - ETA: 0s - loss: 0.1959 - accuracy: 0.9276\n",
      "Epoch 65: val_accuracy did not improve from 0.90300\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1964 - accuracy: 0.9275 - val_loss: 0.2764 - val_accuracy: 0.9024\n",
      "Epoch 66/100\n",
      "1702/1719 [============================>.] - ETA: 0s - loss: 0.1955 - accuracy: 0.9285\n",
      "Epoch 66: val_accuracy did not improve from 0.90300\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1957 - accuracy: 0.9285 - val_loss: 0.2775 - val_accuracy: 0.8996\n",
      "Epoch 67/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 0.1927 - accuracy: 0.9292\n",
      "Epoch 67: val_accuracy did not improve from 0.90300\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.9292 - val_loss: 0.2666 - val_accuracy: 0.9024\n",
      "Epoch 68/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 0.1912 - accuracy: 0.9296\n",
      "Epoch 68: val_accuracy did not improve from 0.90300\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1911 - accuracy: 0.9296 - val_loss: 0.2714 - val_accuracy: 0.8988\n",
      "Epoch 69/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9300\n",
      "Epoch 69: val_accuracy did not improve from 0.90300\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1895 - accuracy: 0.9300 - val_loss: 0.2736 - val_accuracy: 0.9010\n",
      "Epoch 70/100\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 0.1909 - accuracy: 0.9298\n",
      "Epoch 70: val_accuracy did not improve from 0.90300\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1911 - accuracy: 0.9297 - val_loss: 0.2859 - val_accuracy: 0.9002\n",
      "Epoch 71/100\n",
      "1703/1719 [============================>.] - ETA: 0s - loss: 0.1863 - accuracy: 0.9317\n",
      "Epoch 71: val_accuracy did not improve from 0.90300\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1857 - accuracy: 0.9320 - val_loss: 0.2783 - val_accuracy: 0.8996\n",
      "Epoch 72/100\n",
      "1698/1719 [============================>.] - ETA: 0s - loss: 0.1871 - accuracy: 0.9316\n",
      "Epoch 72: val_accuracy did not improve from 0.90300\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1875 - accuracy: 0.9314 - val_loss: 0.2780 - val_accuracy: 0.9018\n",
      "Epoch 73/100\n",
      "1697/1719 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.9334\n",
      "Epoch 73: val_accuracy did not improve from 0.90300\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1831 - accuracy: 0.9333 - val_loss: 0.2749 - val_accuracy: 0.9018\n",
      "Epoch 73: early stopping\n",
      "\n",
      "‚úÖ Training completed!\n",
      "‚úÖ Total epochs: 73\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 5: Combining Multiple Callbacks\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMBINING MULTIPLE CALLBACKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìå Best Practice:\")\n",
    "print(\"  ‚Ä¢ Use BOTH ModelCheckpoint + EarlyStopping\")\n",
    "print(\"  ‚Ä¢ Checkpoint saves best model\")\n",
    "print(\"  ‚Ä¢ EarlyStopping prevents wasted training time\")\n",
    "\n",
    "# Build new model\n",
    "model_combined = keras.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),  # Add dropout for regularization\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_combined.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create multiple callbacks\n",
    "checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "    \"models/best_combined_model.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_accuracy\",  # Monitor accuracy instead\n",
    "    mode=\"max\",              # Save when accuracy increases\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_cb = callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Combined Callbacks:\")\n",
    "print(\"  1. ModelCheckpoint:\")\n",
    "print(\"     - Monitor: val_accuracy (max)\")\n",
    "print(\"     - Save best only: True\")\n",
    "print(\"\\n  2. EarlyStopping:\")\n",
    "print(\"     - Monitor: val_accuracy (max)\")\n",
    "print(\"     - Patience: 10 epochs\")\n",
    "\n",
    "# Train with both callbacks\n",
    "print(\"\\nüöÄ Training with combined callbacks...\")\n",
    "history_combined = model_combined.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"‚úÖ Total epochs: {len(history_combined.history['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0025ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CUSTOM CALLBACK\n",
      "============================================================\n",
      "\n",
      "üìå Custom Callback Use Cases:\n",
      "  ‚Ä¢ Print custom messages during training\n",
      "  ‚Ä¢ Save extra information (gradients, activations)\n",
      "  ‚Ä¢ Implement custom early stopping logic\n",
      "  ‚Ä¢ Send notifications (email, Slack)\n",
      "\n",
      "üöÄ Training with custom callback...\n",
      "\n",
      "üîî Epoch 5 Summary:\n",
      "   Train Loss: 0.3999\n",
      "   Train Acc: 86.05%\n",
      "   Val Loss: 0.3825\n",
      "   Val Acc: 86.80%\n",
      "\n",
      "üîî Epoch 10 Summary:\n",
      "   Train Loss: 0.3387\n",
      "   Train Acc: 88.12%\n",
      "   Val Loss: 0.3557\n",
      "   Val Acc: 87.16%\n",
      "\n",
      "üîî Epoch 15 Summary:\n",
      "   Train Loss: 0.2999\n",
      "   Train Acc: 89.26%\n",
      "   Val Loss: 0.3311\n",
      "   Val Acc: 87.96%\n",
      "\n",
      "‚úÖ Custom callback executed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 6: Custom Callback\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CUSTOM CALLBACK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìå Custom Callback Use Cases:\")\n",
    "print(\"  ‚Ä¢ Print custom messages during training\")\n",
    "print(\"  ‚Ä¢ Save extra information (gradients, activations)\")\n",
    "print(\"  ‚Ä¢ Implement custom early stopping logic\")\n",
    "print(\"  ‚Ä¢ Send notifications (email, Slack)\")\n",
    "\n",
    "# Define custom callback\n",
    "class PrintEpochResults(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"Called at the end of each epoch\"\"\"\n",
    "        if (epoch + 1) % 5 == 0:  # Print every 5 epochs\n",
    "            print(f\"\\nüîî Epoch {epoch + 1} Summary:\")\n",
    "            print(f\"   Train Loss: {logs['loss']:.4f}\")\n",
    "            print(f\"   Train Acc: {logs['accuracy']*100:.2f}%\")\n",
    "            print(f\"   Val Loss: {logs['val_loss']:.4f}\")\n",
    "            print(f\"   Val Acc: {logs['val_accuracy']*100:.2f}%\")\n",
    "\n",
    "# Build model\n",
    "model_custom = keras.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_custom.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create custom callback\n",
    "custom_cb = PrintEpochResults()\n",
    "\n",
    "print(\"\\nüöÄ Training with custom callback...\")\n",
    "history_custom = model_custom.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[custom_cb],\n",
    "    verbose=0  # Silent, let custom callback handle printing\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Custom callback executed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4773106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TENSORBOARD - TRAINING VISUALIZATION\n",
      "============================================================\n",
      "\n",
      "üìå TensorBoard Features:\n",
      "  ‚Ä¢ Real-time training metrics visualization\n",
      "  ‚Ä¢ Model graph visualization\n",
      "  ‚Ä¢ Histogram of weights/gradients\n",
      "  ‚Ä¢ Embedding visualization\n",
      "  ‚Ä¢ Profile training performance\n",
      "\n",
      "üìÅ Log directory: logs\\run_1767293354\n",
      "\n",
      "‚öôÔ∏è TensorBoard Settings:\n",
      "  Log directory: logs\\run_1767293354\n",
      "  Histogram freq: 1 (every epoch)\n",
      "  Write graph: True\n",
      "  Profile batch: 500-520\n",
      "\n",
      "üöÄ Training with TensorBoard logging...\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7245 - accuracy: 0.7638 - val_loss: 0.5181 - val_accuracy: 0.8216\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4871 - accuracy: 0.8293 - val_loss: 0.4406 - val_accuracy: 0.8496\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4417 - accuracy: 0.8451 - val_loss: 0.5268 - val_accuracy: 0.8046\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4148 - accuracy: 0.8557 - val_loss: 0.3961 - val_accuracy: 0.8660\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3961 - accuracy: 0.8618 - val_loss: 0.3776 - val_accuracy: 0.8680\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3773 - accuracy: 0.8673 - val_loss: 0.3728 - val_accuracy: 0.8744\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3649 - accuracy: 0.8717 - val_loss: 0.3653 - val_accuracy: 0.8756\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3534 - accuracy: 0.8745 - val_loss: 0.3927 - val_accuracy: 0.8614\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3429 - accuracy: 0.8792 - val_loss: 0.3538 - val_accuracy: 0.8722\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3335 - accuracy: 0.8817 - val_loss: 0.3547 - val_accuracy: 0.8732\n",
      "\n",
      "‚úÖ Training with TensorBoard completed!\n",
      "\n",
      "üìä To view TensorBoard:\n",
      "  1. Open terminal/command prompt\n",
      "  2. Run: tensorboard --logdir=logs\n",
      "  3. Open browser: http://localhost:6006\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 7: TensorBoard - Visualization Tool\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TENSORBOARD - TRAINING VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìå TensorBoard Features:\")\n",
    "print(\"  ‚Ä¢ Real-time training metrics visualization\")\n",
    "print(\"  ‚Ä¢ Model graph visualization\")\n",
    "print(\"  ‚Ä¢ Histogram of weights/gradients\")\n",
    "print(\"  ‚Ä¢ Embedding visualization\")\n",
    "print(\"  ‚Ä¢ Profile training performance\")\n",
    "\n",
    "# Create log directory with timestamp\n",
    "import time\n",
    "log_dir = os.path.join(\"logs\", f\"run_{int(time.time())}\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ Log directory: {log_dir}\")\n",
    "\n",
    "# Build model\n",
    "model_tb = keras.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_tb.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create TensorBoard callback\n",
    "tensorboard_cb = callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,      # Log weight histograms every epoch\n",
    "    write_graph=True,      # Visualize model graph\n",
    "    write_images=False,    # Don't save layer outputs as images\n",
    "    update_freq='epoch',   # Update logs every epoch\n",
    "    profile_batch='500,520'  # Profile batches 500-520\n",
    ")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è TensorBoard Settings:\")\n",
    "print(f\"  Log directory: {log_dir}\")\n",
    "print(f\"  Histogram freq: 1 (every epoch)\")\n",
    "print(f\"  Write graph: True\")\n",
    "print(f\"  Profile batch: 500-520\")\n",
    "\n",
    "# Train with TensorBoard\n",
    "print(\"\\nüöÄ Training with TensorBoard logging...\")\n",
    "history_tb = model_tb.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[tensorboard_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training with TensorBoard completed!\")\n",
    "print(f\"\\nüìä To view TensorBoard:\")\n",
    "print(f\"  1. Open terminal/command prompt\")\n",
    "print(f\"  2. Run: tensorboard --logdir=logs\")\n",
    "print(f\"  3. Open browser: http://localhost:6006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a713c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LEARNING RATE SCHEDULER\n",
      "============================================================\n",
      "\n",
      "üìå Why Schedule Learning Rate?\n",
      "  ‚Ä¢ Start with large LR for fast initial progress\n",
      "  ‚Ä¢ Reduce LR later for fine-tuning\n",
      "  ‚Ä¢ Helps escape local minima\n",
      "  ‚Ä¢ Improves final accuracy\n",
      "\n",
      "‚öôÔ∏è Learning Rate Schedule:\n",
      "  Epochs 0-9:   LR = 0.01\n",
      "  Epochs 10-19: LR = 0.005\n",
      "  Epochs 20+:   LR = 0.001\n",
      "\n",
      "üöÄ Training with LR scheduler...\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7195 - accuracy: 0.7624 - val_loss: 0.5233 - val_accuracy: 0.8244 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4871 - accuracy: 0.8294 - val_loss: 0.4382 - val_accuracy: 0.8442 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4429 - accuracy: 0.8446 - val_loss: 0.5310 - val_accuracy: 0.8022 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4168 - accuracy: 0.8549 - val_loss: 0.3993 - val_accuracy: 0.8630 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3983 - accuracy: 0.8608 - val_loss: 0.3788 - val_accuracy: 0.8686 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3796 - accuracy: 0.8665 - val_loss: 0.3733 - val_accuracy: 0.8742 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3669 - accuracy: 0.8714 - val_loss: 0.3672 - val_accuracy: 0.8748 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3553 - accuracy: 0.8745 - val_loss: 0.3928 - val_accuracy: 0.8610 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3446 - accuracy: 0.8778 - val_loss: 0.3545 - val_accuracy: 0.8714 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3352 - accuracy: 0.8811 - val_loss: 0.3496 - val_accuracy: 0.8782 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3175 - accuracy: 0.8877 - val_loss: 0.3382 - val_accuracy: 0.8814 - lr: 0.0050\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3124 - accuracy: 0.8897 - val_loss: 0.3348 - val_accuracy: 0.8822 - lr: 0.0050\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3084 - accuracy: 0.8911 - val_loss: 0.3314 - val_accuracy: 0.8844 - lr: 0.0050\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3049 - accuracy: 0.8917 - val_loss: 0.3388 - val_accuracy: 0.8804 - lr: 0.0050\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3005 - accuracy: 0.8927 - val_loss: 0.3276 - val_accuracy: 0.8850 - lr: 0.0050\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2972 - accuracy: 0.8948 - val_loss: 0.3206 - val_accuracy: 0.8848 - lr: 0.0050\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2935 - accuracy: 0.8955 - val_loss: 0.3458 - val_accuracy: 0.8760 - lr: 0.0050\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2898 - accuracy: 0.8971 - val_loss: 0.3225 - val_accuracy: 0.8862 - lr: 0.0050\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2866 - accuracy: 0.8983 - val_loss: 0.3204 - val_accuracy: 0.8878 - lr: 0.0050\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2835 - accuracy: 0.8985 - val_loss: 0.3255 - val_accuracy: 0.8822 - lr: 0.0050\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2720 - accuracy: 0.9040 - val_loss: 0.3121 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2708 - accuracy: 0.9044 - val_loss: 0.3121 - val_accuracy: 0.8884 - lr: 0.0010\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2700 - accuracy: 0.9041 - val_loss: 0.3110 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2692 - accuracy: 0.9047 - val_loss: 0.3123 - val_accuracy: 0.8862 - lr: 0.0010\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2687 - accuracy: 0.9050 - val_loss: 0.3136 - val_accuracy: 0.8884 - lr: 0.0010\n",
      "\n",
      "‚úÖ Training with LR scheduler completed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 8: Learning Rate Scheduler\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LEARNING RATE SCHEDULER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìå Why Schedule Learning Rate?\")\n",
    "print(\"  ‚Ä¢ Start with large LR for fast initial progress\")\n",
    "print(\"  ‚Ä¢ Reduce LR later for fine-tuning\")\n",
    "print(\"  ‚Ä¢ Helps escape local minima\")\n",
    "print(\"  ‚Ä¢ Improves final accuracy\")\n",
    "\n",
    "# Define learning rate schedule function\n",
    "def scheduler(epoch, lr):\n",
    "    \"\"\"Reduce LR by half every 5 epochs\"\"\"\n",
    "    if epoch < 10:\n",
    "        return 0.01\n",
    "    elif epoch < 20:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "# Create LearningRateScheduler callback\n",
    "lr_scheduler_cb = callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
    "\n",
    "# Build model\n",
    "model_lr = keras.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_lr.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Learning Rate Schedule:\")\n",
    "print(\"  Epochs 0-9:   LR = 0.01\")\n",
    "print(\"  Epochs 10-19: LR = 0.005\")\n",
    "print(\"  Epochs 20+:   LR = 0.001\")\n",
    "\n",
    "# Train with LR scheduler\n",
    "print(\"\\nüöÄ Training with LR scheduler...\")\n",
    "history_lr = model_lr.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=25,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training with LR scheduler completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320d0811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REDUCELRONPLATEAU - ADAPTIVE LEARNING RATE\n",
      "============================================================\n",
      "\n",
      "üìå ReduceLROnPlateau:\n",
      "  ‚Ä¢ Automatically reduce LR when metric stops improving\n",
      "  ‚Ä¢ More adaptive than fixed schedule\n",
      "  ‚Ä¢ Monitors validation loss/accuracy\n",
      "\n",
      "‚öôÔ∏è ReduceLROnPlateau Settings:\n",
      "  Monitor: val_loss\n",
      "  Factor: 0.5 (reduce by half)\n",
      "  Patience: 3 epochs\n",
      "  Min LR: 0.0001\n",
      "\n",
      "üöÄ Training with ReduceLROnPlateau...\n",
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7187 - accuracy: 0.7635 - val_loss: 0.5105 - val_accuracy: 0.8284 - lr: 0.0100\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4811 - accuracy: 0.8304 - val_loss: 0.4323 - val_accuracy: 0.8522 - lr: 0.0100\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4367 - accuracy: 0.8448 - val_loss: 0.5058 - val_accuracy: 0.8118 - lr: 0.0100\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4109 - accuracy: 0.8566 - val_loss: 0.3948 - val_accuracy: 0.8640 - lr: 0.0100\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3933 - accuracy: 0.8616 - val_loss: 0.3789 - val_accuracy: 0.8660 - lr: 0.0100\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3752 - accuracy: 0.8678 - val_loss: 0.3741 - val_accuracy: 0.8696 - lr: 0.0100\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3638 - accuracy: 0.8711 - val_loss: 0.3627 - val_accuracy: 0.8712 - lr: 0.0100\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3527 - accuracy: 0.8738 - val_loss: 0.3892 - val_accuracy: 0.8602 - lr: 0.0100\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3424 - accuracy: 0.8790 - val_loss: 0.3575 - val_accuracy: 0.8686 - lr: 0.0100\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3334 - accuracy: 0.8809 - val_loss: 0.3485 - val_accuracy: 0.8716 - lr: 0.0100\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3251 - accuracy: 0.8835 - val_loss: 0.3479 - val_accuracy: 0.8740 - lr: 0.0100\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3161 - accuracy: 0.8870 - val_loss: 0.3375 - val_accuracy: 0.8778 - lr: 0.0100\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3089 - accuracy: 0.8891 - val_loss: 0.3352 - val_accuracy: 0.8836 - lr: 0.0100\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3028 - accuracy: 0.8901 - val_loss: 0.3492 - val_accuracy: 0.8704 - lr: 0.0100\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2956 - accuracy: 0.8930 - val_loss: 0.3290 - val_accuracy: 0.8818 - lr: 0.0100\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2900 - accuracy: 0.8964 - val_loss: 0.3172 - val_accuracy: 0.8844 - lr: 0.0100\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2844 - accuracy: 0.8969 - val_loss: 0.3692 - val_accuracy: 0.8702 - lr: 0.0100\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2783 - accuracy: 0.8997 - val_loss: 0.3205 - val_accuracy: 0.8880 - lr: 0.0100\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2737 - accuracy: 0.9014 - val_loss: 0.3119 - val_accuracy: 0.8904 - lr: 0.0100\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2681 - accuracy: 0.9037 - val_loss: 0.3274 - val_accuracy: 0.8806 - lr: 0.0100\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2626 - accuracy: 0.9061 - val_loss: 0.3071 - val_accuracy: 0.8878 - lr: 0.0100\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2579 - accuracy: 0.9072 - val_loss: 0.2998 - val_accuracy: 0.8934 - lr: 0.0100\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2537 - accuracy: 0.9086 - val_loss: 0.3036 - val_accuracy: 0.8912 - lr: 0.0100\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2489 - accuracy: 0.9092 - val_loss: 0.3141 - val_accuracy: 0.8888 - lr: 0.0100\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2448 - accuracy: 0.9115 - val_loss: 0.2993 - val_accuracy: 0.8914 - lr: 0.0100\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2400 - accuracy: 0.9137 - val_loss: 0.3064 - val_accuracy: 0.8906 - lr: 0.0100\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2367 - accuracy: 0.9153 - val_loss: 0.2994 - val_accuracy: 0.8944 - lr: 0.0100\n",
      "Epoch 28/30\n",
      "1702/1719 [============================>.] - ETA: 0s - loss: 0.2326 - accuracy: 0.9174\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2325 - accuracy: 0.9173 - val_loss: 0.3120 - val_accuracy: 0.8906 - lr: 0.0100\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2168 - accuracy: 0.9232 - val_loss: 0.2987 - val_accuracy: 0.8932 - lr: 0.0050\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2140 - accuracy: 0.9246 - val_loss: 0.2996 - val_accuracy: 0.8948 - lr: 0.0050\n",
      "\n",
      "‚úÖ Training with ReduceLROnPlateau completed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 9: ReduceLROnPlateau - Adaptive LR\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REDUCELRONPLATEAU - ADAPTIVE LEARNING RATE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìå ReduceLROnPlateau:\")\n",
    "print(\"  ‚Ä¢ Automatically reduce LR when metric stops improving\")\n",
    "print(\"  ‚Ä¢ More adaptive than fixed schedule\")\n",
    "print(\"  ‚Ä¢ Monitors validation loss/accuracy\")\n",
    "\n",
    "# Build model\n",
    "model_plateau = keras.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_plateau.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create ReduceLROnPlateau callback\n",
    "reduce_lr_cb = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,           # Reduce LR by half\n",
    "    patience=3,           # After 3 epochs without improvement\n",
    "    min_lr=0.0001,        # Don't go below this\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è ReduceLROnPlateau Settings:\")\n",
    "print(\"  Monitor: val_loss\")\n",
    "print(\"  Factor: 0.5 (reduce by half)\")\n",
    "print(\"  Patience: 3 epochs\")\n",
    "print(\"  Min LR: 0.0001\")\n",
    "\n",
    "# Train with ReduceLROnPlateau\n",
    "print(\"\\nüöÄ Training with ReduceLROnPlateau...\")\n",
    "history_plateau = model_plateau.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[reduce_lr_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training with ReduceLROnPlateau completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1b64a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CALLBACKS SUMMARY\n",
      "============================================================\n",
      "\n",
      "====================================================================================================\n",
      "             Callback                           Purpose                 Key Parameters                 Use Case\n",
      "      ModelCheckpoint     Save best model automatically        save_best_only, monitor Always use in production\n",
      "        EarlyStopping Stop training when no improvement patience, restore_best_weights  Always use to save time\n",
      "          TensorBoard   Visualize training in real-time        log_dir, histogram_freq       Debug & experiment\n",
      "LearningRateScheduler                 Fixed LR schedule             scheduler function   Known optimal schedule\n",
      "    ReduceLROnPlateau             Adaptive LR reduction       factor, patience, min_lr       Unknown optimal LR\n",
      "      Custom Callback      Custom logic during training     on_epoch_end, on_batch_end       Advanced use cases\n",
      "====================================================================================================\n",
      "\n",
      "üéØ BEST PRACTICES:\n",
      "------------------------------------------------------------\n",
      "1. ALWAYS use ModelCheckpoint + EarlyStopping together\n",
      "2. Use TensorBoard for debugging and experimentation\n",
      "3. Use ReduceLROnPlateau for adaptive learning rate\n",
      "4. Create custom callbacks for specific needs\n",
      "\n",
      "üí° PRODUCTION SETUP:\n",
      "------------------------------------------------------------\n",
      "callbacks = [\n",
      "    ModelCheckpoint('best_model.keras', save_best_only=True),\n",
      "    EarlyStopping(patience=10, restore_best_weights=True),\n",
      "    ReduceLROnPlateau(factor=0.5, patience=5),\n",
      "    TensorBoard(log_dir='logs/')\n",
      "]\n",
      "\n",
      "‚úÖ Callbacks summary completed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BLOCK 10: Summary - All Callbacks\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CALLBACKS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary_data = {\n",
    "    'Callback': [\n",
    "        'ModelCheckpoint',\n",
    "        'EarlyStopping',\n",
    "        'TensorBoard',\n",
    "        'LearningRateScheduler',\n",
    "        'ReduceLROnPlateau',\n",
    "        'Custom Callback'\n",
    "    ],\n",
    "    'Purpose': [\n",
    "        'Save best model automatically',\n",
    "        'Stop training when no improvement',\n",
    "        'Visualize training in real-time',\n",
    "        'Fixed LR schedule',\n",
    "        'Adaptive LR reduction',\n",
    "        'Custom logic during training'\n",
    "    ],\n",
    "    'Key Parameters': [\n",
    "        'save_best_only, monitor',\n",
    "        'patience, restore_best_weights',\n",
    "        'log_dir, histogram_freq',\n",
    "        'scheduler function',\n",
    "        'factor, patience, min_lr',\n",
    "        'on_epoch_end, on_batch_end'\n",
    "    ],\n",
    "    'Use Case': [\n",
    "        'Always use in production',\n",
    "        'Always use to save time',\n",
    "        'Debug & experiment',\n",
    "        'Known optimal schedule',\n",
    "        'Unknown optimal LR',\n",
    "        'Advanced use cases'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_callbacks = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(df_callbacks.to_string(index=False))\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\nüéØ BEST PRACTICES:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"1. ALWAYS use ModelCheckpoint + EarlyStopping together\")\n",
    "print(\"2. Use TensorBoard for debugging and experimentation\")\n",
    "print(\"3. Use ReduceLROnPlateau for adaptive learning rate\")\n",
    "print(\"4. Create custom callbacks for specific needs\")\n",
    "\n",
    "print(\"\\nüí° PRODUCTION SETUP:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"callbacks = [\")\n",
    "print(\"    ModelCheckpoint('best_model.keras', save_best_only=True),\")\n",
    "print(\"    EarlyStopping(patience=10, restore_best_weights=True),\")\n",
    "print(\"    ReduceLROnPlateau(factor=0.5, patience=5),\")\n",
    "print(\"    TensorBoard(log_dir='logs/')\")\n",
    "print(\"]\")\n",
    "\n",
    "print(\"\\n‚úÖ Callbacks summary completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
