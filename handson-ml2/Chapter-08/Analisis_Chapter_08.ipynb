{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJPZlZSoJbtvOmh7moepsV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamdansyaif/handson-ml2/blob/main/Chapter-08/Analisis_Chapter_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# ğŸ“˜ **Rekap Teori & Analisis Lengkap â€“ Chapter 8: Dimensionality Reduction**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš© **Tujuan Reduksi Dimensi**\n",
        "\n",
        "Reduksi dimensi dilakukan untuk:\n",
        "\n",
        "* ğŸ”§ Menurunkan kompleksitas data\n",
        "* ğŸ’¾ Mengurangi kebutuhan penyimpanan\n",
        "* âš¡ Meningkatkan performa model\n",
        "* ğŸ‘ï¸â€ğŸ—¨ï¸ Memvisualisasikan data tinggi ke dimensi rendah\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”· **1. Manual PCA via SVD (Singular Value Decomposition)**\n",
        "\n",
        "### ğŸ“Œ *Teori:*\n",
        "\n",
        "* PCA mencari arah (vektor) baru yang menjelaskan varian data terbesar.\n",
        "* Langkah:\n",
        "\n",
        "  1. Center data (mean=0)\n",
        "  2. Gunakan SVD â†’ hasilkan Váµ€ (eigenvektor)\n",
        "  3. Proyeksikan data ke beberapa vektor utama\n",
        "\n",
        "### ğŸ“¦ *Kode:*\n",
        "\n",
        "* Dataset 3D buatan â†’ `np.linalg.svd`\n",
        "* Ambil `Vt.T[:, :2]` â†’ proyeksi ke 2D\n",
        "\n",
        "### ğŸ§  *Analisis:*\n",
        "\n",
        "* MSE rekonstruksi rendah â†’ PCA efektif\n",
        "* Komponen utama (PC1 & PC2) berhasil menangkap mayoritas informasi\n",
        "* Visualisasi menunjukkan arah PC1 dan PC2 pada data 3D (âœ”ï¸ visual fig 8â€“2 & fig 8â€“3)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¶ **2. PCA dengan Scikit-Learn**\n",
        "\n",
        "### ğŸ“Œ *Teori:*\n",
        "\n",
        "* `PCA(n_components=k)` otomatis:\n",
        "\n",
        "  * Center data\n",
        "  * Gunakan SVD internal\n",
        "  * Transform dan inverse transform data\n",
        "\n",
        "### ğŸ“¦ *Kode:*\n",
        "\n",
        "```python\n",
        "pca = PCA(n_components=2)\n",
        "X_2d = pca.fit_transform(X_centered)\n",
        "```\n",
        "\n",
        "### ğŸ§  *Analisis:*\n",
        "\n",
        "* Korelasi tinggi dengan versi manual (Â±1)\n",
        "* Lebih efisien dan bisa langsung `.inverse_transform` untuk rekonstruksi\n",
        "* Cocok untuk pipeline produksi\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ˆ **3. Explained Variance & Elbow Curve**\n",
        "\n",
        "### ğŸ“Œ *Teori:*\n",
        "\n",
        "* `explained_variance_ratio_` menunjukkan proporsi varian yang dijelaskan tiap PC\n",
        "* `np.cumsum(...)` digunakan untuk menentukan jumlah komponen optimal\n",
        "\n",
        "### ğŸ“¦ *Kode:*\n",
        "\n",
        "* Elbow plot visual\n",
        "* Cari jumlah komponen â‰¥ 95% variansi â†’ `argmax(cumsum >= 0.95) + 1`\n",
        "\n",
        "### ğŸ§  *Analisis:*\n",
        "\n",
        "* Threshold 95% sering digunakan sebagai titik optimal\n",
        "* PCA â‰ˆ lossy compression, tapi tetap menjaga struktur penting\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¤ **4. PCA pada Dataset MNIST (784 âœ \\~150 komponen)**\n",
        "\n",
        "### ğŸ“Œ *Teori:*\n",
        "\n",
        "* Dataset gambar bisa direpresentasikan dalam dimensi lebih rendah tanpa kehilangan makna visual\n",
        "* PCA cocok untuk kompresi dan persiapan klasifikasi/clustering\n",
        "\n",
        "### ğŸ“¦ *Kode:*\n",
        "\n",
        "* `PCA(n_components=...)` â†’ reduksi MNIST\n",
        "* `inverse_transform` â†’ bandingkan gambar asli vs hasil kompresi\n",
        "\n",
        "### ğŸ§  *Analisis:*\n",
        "\n",
        "* Gambar masih dapat dikenali\n",
        "* \\~150 komponen cukup menjelaskan â‰¥95% informasi\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§¿ **5. Visualisasi PCA 2D MNIST**\n",
        "\n",
        "### ğŸ“Œ *Teori:*\n",
        "\n",
        "* PCA bisa digunakan untuk visualisasi distribusi data dalam 2D\n",
        "\n",
        "### ğŸ“¦ *Kode:*\n",
        "\n",
        "* Scatter plot tiap digit â†’ `plt.scatter(X_pca[:,0], X_pca[:,1])`\n",
        "\n",
        "### ğŸ§  *Analisis:*\n",
        "\n",
        "* Terlihat ada klaster digit meskipun sebagian overlap\n",
        "* PCA linear â†’ tidak selalu memisahkan klaster dengan jelas\n",
        "\n",
        "---\n",
        "\n",
        "## â™»ï¸ **6. Incremental PCA (Mini-Batch)**\n",
        "\n",
        "### ğŸ“Œ *Teori:*\n",
        "\n",
        "* Cocok untuk dataset besar (streaming atau tidak muat RAM)\n",
        "* Dilatih secara batch dengan `.partial_fit()`\n",
        "\n",
        "### ğŸ“¦ *Kode:*\n",
        "\n",
        "```python\n",
        "ipca = IncrementalPCA(n_components=..., batch_size=...)\n",
        "ipca.partial_fit(X_batch)\n",
        "```\n",
        "\n",
        "### ğŸ§  *Analisis:*\n",
        "\n",
        "* Rekonstruksi mirip dengan PCA biasa\n",
        "* Efisien untuk big data / edge devices\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“¦ **7. Simulasi Incremental PCA untuk Dataset Besar**\n",
        "\n",
        "### ğŸ“Œ *Teori:*\n",
        "\n",
        "* Gunakan generator/data chunk untuk simulasi data besar\n",
        "* Proses batch-by-batch untuk PCA streaming\n",
        "\n",
        "### ğŸ“¦ *Kode:*\n",
        "\n",
        "* `make_classification()` + `data_generator()` + `partial_fit`\n",
        "* Visualisasi explained variance dan proyeksi 2D (sample batch)\n",
        "\n",
        "### ğŸ§  *Analisis:*\n",
        "\n",
        "* Incremental PCA tetap bisa menjaga variansi dominan\n",
        "* Visualisasi 2D tetap menunjukkan distribusi yang masuk akal\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒ **8. t-SNE (Non-Linear Projection)**\n",
        "\n",
        "### ğŸ“Œ *Teori:*\n",
        "\n",
        "* Menjaga hubungan **lokal** antar data\n",
        "* Cocok untuk **visualisasi klaster non-linear**\n",
        "* Tidak bisa `.transform()` data baru\n",
        "\n",
        "### ğŸ“¦ *Kode:*\n",
        "\n",
        "```python\n",
        "TSNE(n_components=2, perplexity=30, max_iter=1000).fit_transform(X)\n",
        "```\n",
        "\n",
        "### ğŸ§  *Analisis:*\n",
        "\n",
        "* Klaster digit MNIST sangat jelas â†’ cocok untuk interpretasi visual\n",
        "* Performa lambat, hanya untuk visualisasi\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒ€ **9. LLE (Locally Linear Embedding)**\n",
        "\n",
        "### ğŸ“Œ *Teori:*\n",
        "\n",
        "* Menjaga representasi lokal via kombinasi linier tetangga\n",
        "* Berguna untuk data di manifold non-linear (misalnya permukaan melengkung)\n",
        "\n",
        "### ğŸ“¦ *Kode:*\n",
        "\n",
        "```python\n",
        "LocallyLinearEmbedding(n_components=2, n_neighbors=10).fit_transform(X)\n",
        "```\n",
        "\n",
        "### ğŸ§  *Analisis:*\n",
        "\n",
        "* Struktur manifold terlihat\n",
        "* Tidak bisa `.transform()` â†’ bukan untuk prediksi\n",
        "\n",
        "---\n",
        "\n",
        "# âœ… **Kesimpulan Akhir â€“ Kapan Pakai Apa**\n",
        "\n",
        "| Teknik          | Gunakan Saat...                      | Bisa Transform Baru? | Visualisasi Bagus? |\n",
        "| --------------- | ------------------------------------ | -------------------- | ------------------ |\n",
        "| PCA             | Linear, cepat, umum digunakan        | âœ…                    | âœ… (terbatas)       |\n",
        "| Incremental PCA | Dataset sangat besar / batch-wise    | âœ…                    | âœ… (opsional)       |\n",
        "| t-SNE           | Ingin lihat klaster secara visual    | âŒ                    | âœ…âœ…                 |\n",
        "| LLE             | Data punya struktur lokal non-linear | âŒ                    | âœ…                  |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wi6k8O3gD2Zl"
      }
    }
  ]
}